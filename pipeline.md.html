<meta charset="utf-8" emacsmode="-*- markdown -*-">

**Pipeline description**

Documentation of the pipeline of producing inference using pseudo code.
Inference is two-fold : *point estimation* and *confidence interval estimation*.


General
===============================================================================

Describes general features shared by all methods.

Simulator
-------------------------------------------------------------------------------

The **simulator** is a program allowing to sample a virtually infinite amount of data points $x$ given some parameters $\mu$ and $\alpha$.

The simulator produces:
- the *observables* as a matrix `X`
- the *labels* as an array `y`
- the sample (importance) *weights* `w`
Usually those 3 elements will be gathered into one object (tuple) named `Data`.

Usage (usually the number of samples will be discarded) :
```python
mu = 1
alpha = 1
Data <- simulator(mu, alpha, n_samples=5000)
#  OR
X, y, w <- simulator(mu, alpha, n_samples=5000)
```



Standard Classifier method
===============================================================================

How to infer using a classifier.

Training the classifier
-------------------------------------------------------------------------------


```python
mu_nominal = 1
alpha_nominal = 1
Data_train_nominal <- simulator(mu_nominal, alpha_nominal)
classifier <- SomeAlgo.fit(Data_train)
```


The log likelihood
-------------------------------------------------------------------------------

The model used here is a Poisson count process in $K$ independent bins indexed by $i$.

\begin{equation}
L(n | \mu, \alpha) = \prod_i Poisson(n_i | \mu \times \gamma_i(\alpha) + \beta_i(\alpha))
\end{equation}
\begin{equation}
L(n | \mu, \alpha) = \prod_i \frac{(\mu \times \gamma_i(\alpha) + \beta_i(\alpha))^{n_i}}{n_i!} e^{ - \mu \times \gamma_i(\alpha) - \beta_i(\alpha)}
\end{equation}

\begin{equation}
\log L(n | \mu, \alpha) = \sum_i n_i \times \log (\mu \times \gamma_i(\alpha) + \beta_i(\alpha)) - \log (n_i!) - \mu \times \gamma_i(\alpha) - \beta_i(\alpha)
\end{equation}

In addition to the Poisson count process the calibration experiment updates our knowledge about the nuisance parameters $\alpha$.
These other measurements `Calib` is taken into account in the likelihood.

\begin{equation}
L(n, Calib | \mu, \alpha) = \prod_i Poisson(n_i | \mu \times \gamma_i(\alpha) + \beta_i(\alpha)) \times L_{Calib}
\end{equation}

Very often $L_{Calib}$ takes the form of a gaussian.

\begin{equation}
L_{Calib} = Normal(\alpha_c, \sigma_c| \alpha) = \frac{1}{\sigma_c\sqrt{2 \pi}} e^{\frac{(\alpha - \alpha_c)^2}{2 \sigma_c^2}}
\end{equation}

Finally gathering it all :

\begin{equation}
\log L(n | \mu, \alpha) = \sum_i n_i \times \log (\mu \times \gamma_i(\alpha) + \beta_i(\alpha)) - \log (n_i!) - \mu \times \gamma_i(\alpha) - \beta_i(\alpha)
    - log(\sigma_c) - log(\sqrt{2 \pi}) + \frac{(\alpha - \alpha_c)^2}{2 \sigma_c^2}
\end{equation}


The negative log likelihood is computed via the `formula` function :
```python
def formula(mu, alpha, gamma_i, beta_i, n_i):
  global alpha_c, sigma_c
  nll = poisson_nll( mu * gamma_i + beta_i, n_i ) + gaussian_nll(alpha, alpha_c, sigma_c)
  return nll
```



Measuring the negative log likelihood on one point $(\mu, \alpha)$
-------------------------------------------------------------------------------

```python
def compute_nll(mu, alpha):
    global classifer  #Â from previous training
    global Data_test <- measurement on real experiment

    Data_valid  <- simulator(mu, alpha)
    signal_valid <- signal_only(Data_valid)
    background_valid <- background_only(Data_valid)

    decision_signal = classifier.predict_score(signal_valid)
    decision_background = classifier.predict_score(background_valid)
    decision_test = classifier.predict_score(Data_test)

    gamma_i = bining(decision_signal)
    beta_i  = bining(decision_background)
    n_i     = bining(decision_test)

    nll = formula(mu, alpha, gamma_i, beta_i, n_i)
    return nll
```

Unfortunately to compute the NLL of a candidate value $(\mu, \alpha)$ one has to rerun the simulation.
Of course the full simulation is not rerun.
Many nuisance parameters influence starts at a late stage of the simulation process and only this last part is required to be rerun.


Point estimation
-------------------------------------------------------------------------------

We want to get $(\hat \mu, \hat \alpha)$ the maximum likelihood estimator for $L$.
If a analytical formulas cannot be derived from the likelihood a numerical approach is the way to go.

Basically any minimizer can do the jobs.
**Minuit** is the standard for negative log likelihood minimization in HEP.
It assumes that the given function is smooth and allow only one minimum which is very often the case in physics settings.


```python
# Point estimation
mu_mle, alpha_mle = Minuit.mingrad(compute_nll)
```

Here is a sketch for a gradient descent algorithm.
```python
# exemple de minimisation
start_mu = 1
start_alpha = 1

current_mu = start_mu
current_alpha = start_alpha
while not convergence:
    left_value = compute_nll(current_mu - epsilon, current_alpha - epsilon)
    right_value = compute_nll(current_mu + epsilon, current_alpha + epsilon)
    gradient = (right_value - left_value) / (2 * epsilon)
    step = ...
    next_mu = current_mu - step
    next_alpha = current_alpha - step
    convergence = is_convergence(...)
```
What I want to emphasize here is that `compute_nll` may be called many times before convergence.
Unfortunatelly memoizing is not possible because the candidate values of $(\mu, \alpha)$ are different for each call.

Moreover gradient descent methods requires to estimate local gradient (and hessian) with scales teribly with increasing the number of parameters.





Confidence interval
-------------------------------------------------------------------------------

Confidence interval are computed by inverting a hypothesis test.

$H_0(\mu = \hat \mu)$ and $H_1(\mu \neq \hat \mu)$.

A likelihood ratio test is conduct and the acceptance region is taken as the confidence interval.

TODO : find again why this is supposed to cover.




Confidence interval estimation
-------------------------------------------------------------------------------

The previous methods work fine when analytical formulas are available.
But in our case closed form formulas are not available.

TODO : use the fact that in large sample limits it tends to a chi-squared distribution and derive the "ln + 1/2" method from it.



Gathering it all
-------------------------------------------------------------------------------

Here are the steps :
1. Train a Classifier
2. Choose good starting points for NLL minimization
3. Use `Minuit.mingrad` to estimate the maximum likelihood
  * numerous calls of the `classifier.decision` and `simulator`
4. Use `Minuit.minos` to estimate the confidence interval
  * even more calls of the `classifier.decision` and `simulator`

Alternative to `Minuit.minos` is to use the hessian to estimate the confidence interval.
Cheaper but symetric, less precise, assumes hyperbolic/parabolic NLL.




Systematic aware classfiers
===============================================================================

Differences with the Standard classifier pipeline
-------------------------------------------------------------------------------




Inferno
===============================================================================

Differences with the Standard classifier pipeline
-------------------------------------------------------------------------------



Training
-------------------------------------------------------------------------------



Differences with my implementations
===============================================================================


Simulated Test set
-------------------------------------------------------------------------------

Since the test set is not available we use the simulator to produce the test set.
The hidden values of the input parameters are noted $\mu^\star$ and $\alpha^\star$.

```python
mu_star = 1.1  # for example
alpha_star = 1.03  # for example
Data_test <- simulator(mu_star, alpha_star)
```

The objective is to measure how well the various models manage to find $\mu^\star$ and $\alpha^\star$.



Hessian confidence interval
-------------------------------------------------------------------------------

Instead of the ln + 1/2 method with profile likelihood we use the Hessian as an approximation.
This gives a symetric interval assuming that the negative log likelihood is parabolic/hyperbolic around the minimum (gaussian-like approximation).
TODO : check if hyperbolic or parabolic ?




<!-- <link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/dark.css?"> -->
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
