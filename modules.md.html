<meta charset="utf-8" emacsmode="-*- markdown -*-">

**Modules**

Description des différentes parties du montage expérimental.


Généralités
===============================================================================

Notations / Glossary
-------------------------------------------------------------------------------

- $\mu$ : the parameter of interest (in general)
- $\alpha$ : the nuisance parameter (in general)
- $\mu^\star$ : the true unknown value of the parameter of interest that generated experimental data
- $\alpha^\star$ : the true unknown value of the nuisance parameter that generated experimental data
- $\hat \mu$ : the estimator of the parameter of interest
- $\hat \alpha$ : the estimator of the nuisance parameter
- $\gamma$ : the expected number of signal events
- $\beta$ : the expected number of background events
- $\gamma_i$ : the expected number of signal events in bin number $i$
- $\beta_i$ : the expected number of background events in bin number $i$
- X : les observables
- y : les labels
- w : les poids
- Data : (X, y, w)
- v : negative log-likelihood value
- d : reduction of X to 1D (classifier decision for example)

!!! WARNING
    Pour alléger les notations dans les schémas les données ou valeurs calculées peuvent utiliser les mêmes lettres.
    Les lettres (X, v, d, etc) servent surtout à décrire la nature de la grandeur (dataset, valeur de NLL, décision d'un classifieur, etc).
    Les données ayant les mêmes lettres ne contiennent pas les mêmes valeurs si elles n'ont pas été obtenue par le même chemin de calcul.

Estimateurs des paramètres
-------------------------------------------------------------------------------

L'objectif des processus décris ici est d'estimer la valeur et l'intervalle de confiance du paramètre d'intérêt.
L'estimateur que l'on utilise est le maximum likelihood.

On va donc chercher les valeurs des paramètres $\mu$ et $\alpha$ qui maximise la probabilité d'avoir généré les données observés $X$.

\begin{equation}
  \hat \mu, \hat \alpha = argmax_{\mu, \alpha} p(X | \mu, \alpha)
\end{equation}

Puis l'intervalle de confiance est estimé à partir de se maximum par une méthode graphique.


Estimateurs de l'intervalle
-------------------------------------------------------------------------------

L'estimation de l'intervalle de confiance est réalisé par une méthode graphique.

Confidence interval are computed by inverting a hypothesis test.

$H_0(\mu = \hat \mu)$ and $H_1(\mu \neq \hat \mu)$.

A likelihood ratio test is conduct and the acceptance region is taken as the confidence interval.

A standard likelihood ratio looks like :
\begin{equation}
\lambda =  \frac{L(Data | \mu \neq \hat \mu)}{L(Data | \mu = \hat \mu)}
\end{equation}

But to get rid of the nuisance parameter $\alpha$ there is 2 options :
1. Marginalization
2. Profiled likelihood

The second is prefered in our case for yet-to-discovered reasons.

!!! Tip
    I could not find why marginalization is not even considered in the papers I read.

A profiled likelihood test is conduct "and inverted" to compute the confidence interval of $\star \mu$.

\begin{equation}
\lambda(\mu, Data) =  \frac{\sup_{\alpha} L(Data | \mu \neq \hat \mu, \alpha)}{\sup_{\mu, \alpha} L(Data | \mu, \alpha)}
\end{equation}
\begin{equation}
\lambda(\mu, Data) =  \frac{\sup_{\alpha} L(Data | \mu \neq \hat \mu, \alpha)}{L(Data | \hat \mu, \hat \alpha)}
\end{equation}


This method works fine when analytical formulas are available.
But in our case closed form formulas are not available.

According to **Wilks theorem** :
the distribution of $−2 \log [ \lambda (\mu, Data) ]$ is approximately a $\chi^2_p$ with $p$ degrees of freedom, $p$ being the dimension of $\mu$.


!!! WARNING
    TODO : Explain from here the ln + 1/2 method to estimate the confidence interval

!!! WARNING
    TODO : find again why this is supposed to cover.

!!! ERROR
    TODO : Explain that Minos algorithm does not work in our case + the Hessian inverse approximation










Le pipeline idéale
===============================================================================

Le pipeline idéale consiste à utiliser directement la likelihood du modèle génératif.
Le maximum likelihood est obtenu par une minimisation numérique de la negative log likelihood.

Le principale point sur lequel les pipelines diffèrent est sur le calcul de la likelihood.

Ici est présenté le pipeline idéale donnant les performances optimales.
Ce pipeline est réalisable sur les toys et permet de comparer les performances des autres pipelines au maximum théorique.

Ce pipeline sert de base pour le pipeline classique et hybride.


Boucle d'optimisation
-------------------------------------------------------------------------------

L'optimisation numérique employé est une descente de gradient.
On représente ici la boucle d'optimisation qui met à jour les valeurs de $\mu$ et $\alpha$ à l'aide d'évaluations successive de la NLL afin de se rapprocher du minimum.

![Figure [fig:optimiseur_loop]:
  Optimiseur loop
](./modules/optimiseur_loop.png)

Cette boucle est composé de 3 modules [O] [V] et [G] décrit dans les sections suivantes.


Module V : calcul de la NLL
-------------------------------------------------------------------------------

Le premier calcule la valeur de la negative log likelihood $v$ à partir de valeur des paramètres $\mu$ et $\alpha$.
Dans ce cas de pipeline idéale on applique simplement les formules données par le modèle génératif.

![Figure [fig:nll_value]:
  Negative log likelihood full computation module
](./modules/nll_value.png)

!!! INFO
    réference dans le code : compute_nll()


Module G : calcul du gradient de la NLL
-------------------------------------------------------------------------------

Le second module calcule le gradient de la negative log likelihood $g$ à partir de valeur des paramètres $\mu$ et $\alpha$.

![Figure [fig:gradient]:
  Gradient computation module
](./modules/gradient.png)

Ce module peut être une simple estimation par différence finie.

![Figure [fig:finite-diff]:
  Example of gradient estimation using finite differences
](./modules/finite_difference.png)

Mais en pratique une heuristique (toujours inconnue) est employée afin de trouver la meilleure valeur pour $\epsilon$.

!!! INFO
    réference dans le code : fonction ingerne à Minuit


Module O : mise à jour des paramètres mu et alpha
-------------------------------------------------------------------------------

Et le dernier module est l'optimiseur qui met à jour les valeurs de $\mu$ et $\alpha$ en fonction des valeurs de la NLL $v$ et de son gradient $g$.

L'optimiseur choisi pour réaliser cette minimisation numérique est BFGS.
En effet la pratique montre que souvent la forme de la NLL est convexe proche du minimum.
Il suffit donc de commencer non loin du minimum ce qui est en général possible en science expérimentale car souvent les connaissances du domaine donnent un intervalle assez serré des valeurs probables du paramètre d'intérêt.

![Figure [fig:optimiseur]:
  Optimiseur module
](./modules/optimiseur.png)

La méthode de Nelder–Mead est parfois utilisé alternativement avec BFGS si ce dernier rencontre un problème pour atteindre le minimum.

!!! INFO
    réference dans le code : Minuit.Migrad() [BFGS] et Minuit.simplex() [Nelder-Mead] sont utilisés alternativement afin d'aider à la convergence.









Le pipeline classique
===============================================================================

Dans le cas de HiggsML la likelihood du modèle génératif fait intervenir un très grand nombre de variables latentes.
Calculer la likelihood requiert le calcul irréalisable d'une intégrale de très haute dimension.

On modifie donc le modèle décrivant le processus par un comptage Poissonien.

!!! WARNING
    TODO : ajouter l'explication pour utiliser Poisson (approx de Binomiale, etc) ?

Ce qui rend le calcul de la negative log likelihood plus complexe.
Les modifications de la NLL sont le sujet principal de cette section.


Calcul de la NLL
-------------------------------------------------------------------------------

Le calcul de la NLL inclus de nombreuses étapes dont la construction d'un histogramme visant à diminuer la taille de l'intervalle de confiance.

Le calcul d'un histogramme voit sa complexité croître de façon exponentielle avec le nombre de dimension.
Hors l'intérêt de ces travaux est d'exploiter plus d'observables donc d'augmenter la dimensionnalité des données.
On réalise donc une réduction de dimension à l'aide d'un classifieur (ou d'une autre méthode).

Le schéma général de calcul de la NLL est donc le suivant :

![Figure [fig:value_loop]:
  Zoom on the negative log likelihood value module ($\mu^\star$ et $\alpha^\star$ sont en rouge car l'étoile se voit peu sur le schéma)
](./modules/value_loop.png)



Module S : le simulateur
-------------------------------------------------------------------------------

Le simulateur produit à la demande un dataset $X, y, w$ à partir de la seed $s$ et des paramètres $\mu$ et $\alpha$.

![Figure [fig:simulation]:
  Simulation module
](./modules/simulation.png)


Module XP : les données expérimentales
-------------------------------------------------------------------------------

Les données expérimentales sont générées une seule fois à partir d'une seed $s$ et des "vrais" paramètres caché que les estimateurs doivent retrouver.
En production les données expérimentales proviendrais des mesure faite avec l'appareil de mesure.
Ces données étant confidentielles nous utilisons ici le simulateur avec des valeurs cachées.
Ceci facilite la mesure des performances puisque la vérité terrain est ainsi connue.


![Figure [fig:xp]:
  Experience data
](./modules/experience.png)


Module L : séparation des signaux et background
-------------------------------------------------------------------------------

Les données simulées sont séparées en 2 parties : signaux et backgrounds

![Figure [fig:label]:
  Label filter module
](./modules/label.png)


Module C : classifieur
-------------------------------------------------------------------------------

Les données simulées et expérimentales sont réduites à 1 dimension par un classifieur.
Le classifieur est entraîné en utilisant des données différentes provenant aussi du simulateurs.

La réduction de dimension peut aussi être une simple sélection d'une observable.
Cette méthode ne change rien au pipeline.

![Figure [fig:clf]:
  Classifieur
](./modules/classifieur.png)


Module H : histogramme
-------------------------------------------------------------------------------

Les données réduites servent à produire les summary statistics par construction d'un histogramme.
Ces summary statistics correspondent au nombre attendu par le modèle de signaux dans les bins ($\gamma_i$),
au nombre attendu de backgrounds par le modèle dans les bins ($\beta_i$) et
au nombre d'événement obtenu par l'expérience dans les bins ($n_i$)


![Figure [fig:histogram]:
  Histogram
](./modules/histogram.png)


Module NLL : negative log likelihood
-------------------------------------------------------------------------------

Les summary statistics servent alors à calculer la NLL (simple calcul d'une formule).
La calibration est intégrée dans ce calcul.
La calibration n'est pas représentée sur le schéma pour l'alléger et parce qu'il s'agit d'un élément commun à toutes la variante du pipeline.

\begin{equation}
L(\mu, \alpha) =  Poisson(X | \mu, \alpha) \times Calib(Other measure | \mu, \alpha)
\end{equation}

![Figure [fig:nll]:
  Negative log likelihood formulas computation
](./modules/nll.png)









Les alternatives
===============================================================================


L'estimation directe
-------------------------------------------------------------------------------


!!! WARNING
    TODO


Inferno
-------------------------------------------------------------------------------

La méthode INFERNO combine à la fois la réduction de dimension et la construction d'un histogramme.



Le pipeline hybride
-------------------------------------------------------------------------------

La différence est l'intégration d'une nouvelle mesure sur les données expérimentales s'ajoutant à la formule de la NLL de la même manière que la calibration.

\begin{equation}
  L(\mu, \alpha) =  Poisson(X | \mu, \alpha) \times Calib(Other measure | \alpha) \times N(\alpha | k )
\end{equation}

!!! INFO
    Validité de cette opération statistique ?  X et k ne sont pas indépendant...

![Figure [fig:value_loop_hybrid]:
  Zoom on the negative log likelihood value module using hybrid pipeline
](./modules/value_loop_hybrid.png)


![Figure [fig:regressor]:
  Regressor
](./modules/regressor.png)








Évaluation empirique
===============================================================================


Critères de performance
-------------------------------------------------------------------------------

Les diverses alternatives seront évaluées selon 2 critères :
1. La Mean Squared Error (MSE) de l'estimateur de $\mu$
2. La taille de l'intervalle de confiance

La MSE combine à la fois le biais et la variance de l'estimateur qui sont primordiaux pour une mesure de qualité.
Un estimateur biaisé est un estimateur quasiment inutilisable en Physique (source ?).
De plus une grande variance implique une estimation peu stable donc assez peu satisfaisante.

La MSE est donc la première mesure de performance pour sélectionner les hyper-paramètres des algorithmes de ML impliqué.

La taille de l'intervalle de confiance est précisément ce que l'on souhaite réduire au maximum.
Il représente l'incertitude finale sur le paramètre de nuisance.


Mesure de performance
-------------------------------------------------------------------------------

Afin de mesurer la MSE des estimateurs le processus complet (entraînement et estimation) est répété 30 fois en changeant uniquement la seed.
La seed contrôle à la fois l'échantillonnage du simulateur mais aussi l'initialisation de réseaux de neurones.
On échantillonne ainsi 30 valeurs de $\hat \mu$ et 30 intervalles.

Ces échantillons dépendent des valeurs "vraies" $\mu^\star$ et $\alpha^\star$ choisies.
Afin d'observer les performances en dehors du nominal on utilise 3 valeurs de $\alpha^\star$ : le nominal plus ou moins 1 déviation standard telle que définie par la calibration.
Plusieurs valeurs de $\mu^\star$ sont utilisés :
-  HiggsML [0.5, 1, 1.5, 2]
-  Toy 1D [0.5, 0.75, 1, 1.25, 1.5]
-  Toy 3D [0.5, 1.25, 2]

!!! ERROR
    Et merde ! Le nominal est pas inclus dans le toy 3D.
    À corriger.

Au final plusieurs dizaines d'estimation de $\hat \mu$ et de son intervalle de confiance sont réalisées afin de mesurer empiriquement la MSE et la taille moyenne de l'intervalle de confiance en fonction de $\mu^\star$ et $\alpha^\star$.





Estimateur de mu et de alpha
-------------------------------------------------------------------------------

Lors de la maximisation de la likelihood $\mu$ et $\alpha$ sont traités exactement de la même manière.
C'est uniquement à l'étape de la construction de l'intervalle de confiance ou de l'entraînement des réductions de dimension que la différence entre paramètre d'intérêt et de nuisance intervient.

Les divers estimateurs de $\mu$ et $\alpha$ sont caractérisés par 2 éléments qui définissent la manière de calculer la NLL :
- Le pipeline utilisé
    - idéale
    - classique
    - régression directe
    - hybride
- La réduction de dimension utilisé
    - classifieur classique : Gradient boosting
    - classifieur classique : Neural network
    - data augmentation
    - tangent propagation
    - Pivotal neural network
    - feature filter
    - inferno

Le pipeline idéale ou la régression directe ne requièrent pas de réduction de dimension donc pas de classifieurs ou d'inferno.


Estimateurs de l'intervalle de mu
-------------------------------------------------------------------------------

Identiquement à l'estimation des paramètres du modèle statistique les différences sur l'estimation de l'intervalle de confiance proviennent de la façon de calculer la NLL.



Illustration des résultats
-------------------------------------------------------------------------------

!!! WARNING
    TODO : Quelles tableaux/graphiques pour illustrer mes claims et comment ils sont obtenus

Les performances mesurées sont la MSE et la taille moyenne de l'intervalle de confiance à $\mu^\star$ et $\alpha^\star$ fixé.
Afin de comparer les diverses méthodes on plot sous forme de boite à moustache les critères de performances pour chaque méthode.
Une boite resserrée indique une méthode stable vis-a-vis des variations de $\mu^\star$ et $\alpha^\star$.
La hauteur de la boite (en particulier la médiane) indique la qualité de la méthode (pour les deux critères : lower is better).

Des graphes remplaçant les boites à moustaches par moyenne/variance sont aussi disponible mais moins informatif (trop sensible aux valeurs extrêmes à mon goût).




Claims
===============================================================================


!!! WARNING
    TODO : quels sont mes claims + les illustrations

![Figure [fig:S3D2-Prior]:
  Confidence interval length using classic and ideal pipeline on the 3D toy
](./modules/S3D2-prior_min_avg_mse_N=30000-boxplot_sigma_mean.png)

![Figure [fig:S3D2-Calib]:
  Confidence interval length using hybrid and ideal pipeline on the 3D toy
](./modules/S3D2-calib_min_avg_mse_N=30000-boxplot_sigma_mean.png)


![Figure [fig:HiggsML-Prior]:
  Confidence interval length using classic and ideal pipeline on the HiggsML data
](./modules/HIGGSTES-prior_min_avg_mse_N=-1-boxplot_sigma_mean.png)

![Figure [fig:HiggsML-Prior]:
  Confidence interval length using classic and ideal pipeline on the HiggsML data
](./modules/HIGGSTES-calib_min_avg_mse_N=-1-boxplot_sigma_mean.png)





Le mail
===============================================================================


(1) Schema général “classique”:

[+] FIGURE: faire un graphe avec le pipeline général “classique” des physiciens
		* numéroter les modules
		* pour chaque module, indiquer
			- quelles dont les données d’entrée  (par exemple, l’entrée d’un certain module pourrait être un "dataset d’evènements” ou un batch, ou un seul évènement, ou beta, ou gamma)
			- quelles sont les données de sortie (par exemple mu, alpha, la barre d’erreur de mu, l’incertitude sur la barre d’erreur de mu)

[+] SUPPORT DE FIGURE (texte):
	pour chaque module (identifié par son numéro), indiquer
		* les procédures utilisées avec leur nom
		* leur rôle


(2) Bottlenecks, points sensibles, et méthodes spécifiques:

En se référent au graphe:
		* identifier les modules “sensibles" (avec leur numéro)
		* identifier les méthodes alternatives aux procédures utilisées en (1) que tu as explorées dans ta thèse
Si besoin est: faire un deuxième graphe avec un pipeline alternatif si les méthodes que tu as explorées ne fittent pas bien dans le pipeline classique

(3) Évaluation empirique:
		* Métriques de succès: qu'est-ce qu'on mesure pour comparer les résultats et évaluer les progrès?
		* Estimateurs de mu: faire la liste des méthodes comparées (ou à comparer)
		* Estimateurs de alpha: faire la liste des méthodes comparées (ou à comparer)
		* Estimateurs de l’incertitude sur mu: faire la liste des méthodes comparées (ou à comparer)
		* Comment l'estimer empiriquement la variance des estimateurs de mu, alpha et le barre d’erreur sur mu?
		* Quels graphes ou figures illustrent bien les progrès dans les résultats (donner un exemple typique de chaque graphe avec un texte expliquant comment les interprêter; pas plus de 2 ou 3 graphes)

(4) Claims:
- Faire une liste des résultats empiriques (obtenus ou souhaités si les experiences n’ont pas encore été faites ou sont à refaire) conduisant à des conclusions positives ou négatives
- Faire un graphe (même hypothétique si les résultats ne sont pas encore là) illustrant chaque résultat
- Faire une description du protocole experimental ayant conduit à ces résultats





<!-- <link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/dark.css?"> -->
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
