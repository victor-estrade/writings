<meta charset="utf-8" emacsmode="-*- markdown -*-">

**Plan 1.0**


This document gathers (almost) everything related to our work.
Organize everything to show a possible plan for the thesis.
Since removing parts are easier than adding some, some parts are deliberately too developped.

To help modeling/rearanging the plan the content is broken down to the smallest pieces possible : one (sub-)bullet = one idea.

- Everything should look like claims and/or assetions (maximizing focus on the message).
- Sub-bullets are to be developed into a few sentences or full paragraph (with figures and equations if needed).
- Lonely bullet are ideas that remains to be broken down into smaller pieces or very small sub-sections
- Chapter or section titles are uninspired (improve it later)



High energy physics
===============================================================================

ML to understand the universe
-------------------------------------------------------------------------------

- ML is a very efficient tool to exploit high dimensional or big data produced by modern exprimental science
- Also everywhere CERN
  - To select data (2nd level trigger if I recall correctly)
  - To monitor data quality (Adrian's PhD)
  - To make inference
  - To design apparatus ?
- The importance of Higgs related research
  - Meta-stability of the Universe
  - And other Physics related thing to shine



The importance of uncertainty
-------------------------------------------------------------------------------

- Systematics uncertainty comes from unknown or not well known "influences" on the data/process
  - (Need to break it down)
- Uncertainty from a ML point of view
  - (Need to break it down)
  - Or Point forward ?



The Higgs to tau tau process
-------------------------------------------------------------------------------

- The HiggsML Challenge is one relevant example of ML for HEP (aka the discovery pipeline)
  - Discovery pipeline revolves around statistical test
  - The generative process is complex and involves importance sampling
  - Descibe the features distributions
  - The discovery pipeline involves a classifier
  - The simulator is used to generate training data **but also** to estimate Standard Model predictions
  - Systematic uncertainty have to be taken into account
- Measure Higgs to tau tau cross section uses the exact same dataset but a different approach
  - The parameter of interest relate to the distribution NOT the invidual events
  - Emphasize that the objective is to build a confidence set not only a point estimator
  - The event wise generative likelihood is not tracktable (High dimensional integrals)
  - Point forward to Formal Model Chapter for more information about how to tackle this



Efforts to reconciliate confidence set and individual predictions in ML
-------------------------------------------------------------------------------

- Motivation = Tackling systematics takes a lot of effort (manpower). We are looking for a way to make it easier !
  - Ou plutôt expertise de fragilité. Si on change un truc tout doit être revu pour s'assurer que rien de casse.
- Recent progress in Neural networks toward tackling distributions instead of individual instances
  - Neural Statistician paper
  - Inferno ?
  - PointNet ?
- The remaining of this document :
  - Give more details about the modeling of the problem
  - Explore relevant porposed regularizations from litterature which may help
  - Propose direct regression using a Bayesian point of view
  - Use the direct regression to support the more classical approach by extracting "more" from the data





Formal modeling
===============================================================================


Statistical inference in ideal case
-------------------------------------------------------------------------------

!!!
    Here is introduced the statistical tools required and illustrated with a simple 1D example

- From a simple 1D example : explain the pipeline in an ideal case (separable classes, no systematics)
  - Measuring leaves length $x$ (for whatever reason) with a ruler
  - 2 groups of leaves :
    - 1 following a Gamma distrib (group B)
    - and another longer following a Gaussian distrib (group S)
  - Want to know the number of leaves in group S
  - Want to know the deviation of the $n_S$ from prediction (for numerical convenience)
  - Giving the likelihood of the data : [formula]
- Maximum likelihood point estimator
  - Easy with maximum likelihood !
- Invert statistical test to get a confidence set
  - The final objective is a confidence set (or interval)
  - We get it by inverting a statistical test.


Systematics
-------------------------------------------------------------------------------

!!!
    First difficulty : systematic effect of the nuisance parameters


- What are systematics ?
  - Nuisance parameters are parameters required to fully describes the data generating process but not of direct interest
  - Systematic effect is the effect of nuisance parameters on the data
  - Update the 1D example :
    - Systematics = a small offset or scale factor on the ruler
      - (we go with the scale because it will be usefull later)
      - impossible to disentangle -> measured x = offset + true value or scale * true value
    - Objective = something related with the mean length of the leaves
    - Increases uncertainty on the final measurement
  - Calibration is required to partially disentangle the nuisance parameters and the parameter of interest
    - It is an additionnal information -> an additional measurement -> an additional likelihood
- Systematics always increases the confidence set volume
- Profiled likelihood method to take systematics into account in uncertainty measurement (volume of confidence set)
  - The unified approcah [paper] using profiled likelihood to fix flip-flopping
  - The graphical methods (convergence to chi squared distribution)
  - Some coverage garanties in large samples limit



Classifier to improve binning
-------------------------------------------------------------------------------

!!!
    Second difficulty : High dimensional data

- Binning is better !
  - A good idea to improve the inference is to do binning as long as the Poisson approx remains valid
  - show math proving that 2 bins is better no matter what threshold is used
  - show math proving that more bins is probably better too
  - best to have pure signal or pure background bin
- High dimensional data histogram is too expensive
  - Multi dimensional data usually cary more information
  - Unfortunately binning scales exponentially with increase of dimension
- dimension reduction
  - Need to find a good dimension reduction keeping most information about our parameter of interest
  - Can be crafted by hand but it requires domain knowledge and many work hours
  - hence the idea of using Machine learning
- Figure of merit is not a tracktable (additive) quantity (cannot use as a loss)
  - So we can use a proxy loss to train our ML model
  - Recall that separating S and B events is reduces the uncertainty -> classifiers
- Bayes optimal classifiers gives sufficient summary stat (no systematics setting)
- Systematics breaks Bayes optimal classifier garanty


Solutions and outline (point to next chapters)
-------------------------------------------------------------------------------

- Regularization to train a robust classifier
- Change cross-entropy for a lower bound of final uncertainty
- Direct regression (likelihood free setting)
- Mining data for nuisance parameters to improve model





State of the art
===============================================================================

!!!
    For each method this is the place to disseminate some experimental results illustrating successes and failures of the models

!!! error
    Reprendre les papiers pour compléter

Add regularization to cross entropy loss
-------------------------------------------------------------------------------

- If the classifier output is independant from the nuisance parameters then we win !
  - If it is just less dependant it will still decrease the final uncertainty.



Data augmentation
-------------------------------------------------------------------------------

- Describe method
  - Why it should work
  - How to train it correctly (with details)
- Avantages / drawbacks summary
- Performances



Tangent Propagation
-------------------------------------------------------------------------------

- Describe method
  - Why it should work
  - How to train it correctly (with details)
- Avantages / drawbacks summary
- Performances


Pivotal neural networks
-------------------------------------------------------------------------------

- Related to the DANN but without unlabeled data
- Describe method
  - Why it should work
  - How to train it correctly (with details)
- Avantages / drawbacks summary
- Performances



Neural stat & inferno
-------------------------------------------------------------------------------

- Training neural networks to produce summary statistics
  - Permutation invariant architectures
  - Losses on summary stats (and on samples for neural stat)
- Training on a lower bound of the final uncetrainty
  - Cramer Rao bound
- Limitations (& possible solution)
  - Differentiable simulator
  - (Approximate derivative with tangent)
  - Reverse a large hessian matrix can be complicated
  - (Tackle only the systematic effects with most impact on inference)


Measuring uncertainty in ML
-------------------------------------------------------------------------------

- Importance of uncertainty in ML
- Mixture density networks
  - Predict parameters of distributions (exm : mean and variance of gaussian)
  - Training details
  - The dynamic of training is unusual
  - Adjust Adam parameters to reduce intertia
- Short review of more recent methods
  - MC-dropout
  - Deep ensembles
  - Swag (Stochastic weight averaging - Gaussian)
- Evaluation of uncertainty predictions in machine learning
  - Brier Score and NLL ("proper scoring" ?)
  - No real answer to "Can you trust your uncertainty estimation ?" (error on error)
- Compare uncertainty in ML and Experimental science
  - In ML the target is still the objective. We want the target to be inside the interval and close to the prediction
  - In HEP the target cannot be reached anyway. The interval has coverage anyway : the objective is to reduce the interval.




Proposed solutions
===============================================================================

Direct regression on empirical distribution
-------------------------------------------------------------------------------

- Motivation
  - Likelihood free
  - No differentiable simulator
  - Simpler (therefor less accurate)
  - Faster at inference
- Updating the architecture to tackle empirical distributions
  - Permutation invariant networks
  - Importance that sample size is representative of real data ?
- Include samples weights into the architecture
- Two ways to handle nuisance parameters
  - Ingore them (harder on the network)
  - Profile them (give as input and marginalize)
- These architectures are compatible with Inferno
  - can improve network expressivity



n_i are not sufficient
-------------------------------------------------------------------------------

- $n_i$ are not sufficient for $\alpha$
- Domain knowledge to extract other quantities ?
  - Yes, but it is likely in the calibration already !



Extract using a regressor
-------------------------------------------------------------------------------

- Data mining about distribution parameter without domain knowledge is exactly what direct regression from previous chapter is about.
- Updating the likelihood using this new measurement by simply add another likelihood to it.


Experimental results
-------------------------------------------------------------------------------

See the next chapter ?



Experimental results
===============================================================================

!!!
    Je rassemble les résultats ici.
    Mais en pratique je pense qu'une majorité devrait être distribuée tout le long du manuscrit.
    Ou bien envoyée en annexe.

First the results of the individual methods and a description of their behaviour.
Then comparing using the usual model.
Then comparing using the improved model.


!!! Tip
    Affirmations & interprétation / explications

Classifier
-------------------------------------------------------------------------------

- On 1D toy
  - similar to no dimension reduction (which is expected)
  - biased estimator (which is what we want to avoid)
  - performance depend a lot of sample size (which is expected)
-  On 3D toy
  - TODO
- On higgs
  - TODO update with new results




Data augmentation
-------------------------------------------------------------------------------

- On higgs
  - TODO update with new results


Tangent Propagation
-------------------------------------------------------------------------------

- On higgs
  - TODO update with new results


Pioval network
-------------------------------------------------------------------------------

- On higgs
  - TODO update with new results


Inferno
-------------------------------------------------------------------------------


- On higgs
  - It almost works
  - Sometimes close to constant prediction.


Direct regression
-------------------------------------------------------------------------------

- On 1D toy
  - Blind-reg is way better than the Param-Reg
  - Variance does not vary according to the number of samples



Claim : All methods works (mostly) as expected on toys
-------------------------------------------------------------------------------

- MSE decreases with increasing the number of samples (except Regressor)
- Non robust methods are sensitive to systematic effect
- 1D toy is very easy
  - Classifiers are (almost) optimal for dimension reduction but there is no reducton here
  - the problem could be solved with a linear regression



Claim : The difficulty on Higgs comes only from the rare signal regime (S << B)
-------------------------------------------------------------------------------

- XP showing that just balancing S and B makes the model's behaviour clother to their behaviour on toys
- XP showing that just un-balancing S and B on the toys makes the model's behaviour clother to their behaviour on Higgs



Claim : Extracting nuisance params info from data improves MSE and interval
-------------------------------------------------------------------------------

- On toys
- On higgs
  - the nuisance estimation is often overconfident !
- Models that does not takes much advantage from it are (maybe) doing it internally
  - Inferno could naturally use some of the bins for this purpose (the loss may encourage it)
  - The Blind-regresor could also do it (it is designed with the freedom of fully exploiting the data)
  - what about methods with regularization ? Why don't they also achieve this ?
    - regularized methods loss are expressed at a sample level
    - this information is not available at sample level but only on at a distribution level





Discussion and conclusion
===============================================================================





Lost and found
===============================================================================

- les résultas des XP
- Higgs re-simulator
- 1er Travaux sur sigma mu
- Insister sur le fait que S & B ne sont pas séparable (sinon c'est trop facile)
- Peut-être que le regresseur ne marche pas dans le régime S << B car le ML s'occupe de performance en moyenne et nous on cherche à mesurer un petit bump dans la queue de la distribution. C'est pas quelque chose de commun dans le ML.
- Est-ce que l'échec de Regressor sur Higgs (S << B) ne vient pas d'un sample size trop petit ? 10k events ça donne peut-être une "pente" à fit très variable d'un batch à l'autre !

- How it is done
  - hand crafted dimension reduction (ie ask a theorist to find a feature) is not always possible and requires a lot work hours
  - Poisson count process & binned Poisson count process
  - Although the model seems simple, most of it is in the simulator ie in the estimation of $\gamma$ and $\beta$
- Other methods exists but do not fit perfectly to our problem
  - ABC is likelihood free -> we have a likelihood
  - Variational inference -> is known to underestimate the uncertainty, and is looking for p(x) instead of p(mu|x)
  - Bayesian networks -> Other have tried ... need to check more in depth
  - Mining gold -> I do not have access to the simulator (proprietary code)



<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/dark.css?">
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script>markdeepOptions={tocStyle:'none'};</script>
<!-- Markdeep: --><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
