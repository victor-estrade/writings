<meta charset="utf-8" emacsmode="-*- markdown -*-">

**Plan 1.0**


Positioner le problème
===============================================================================


!!! error
    Ne pas se limiter à l'interval de confiance des physiciens mais aussi inclure les méthodes ML de calcul de confiance
    cf Can you trust your model uncertainty et Evaluating predictive uncertainty challenge





Contexte
-------------------------------------------------------------------------------

- Explosion of ML in experimental science
- LHC at CERN
- HiggsML challenge



Statistical inference in ideal case
-------------------------------------------------------------------------------

!!!
    Here is introduced the statistical tools required and illustrated with a simple 1D example

- Introduce the 1D example
  - Measuring leaves length $x$ (for whatever reason) with a ruler
  - 2 groups of leaves :
    - 1 following a Gamma distrib (group B)
    - and another longer following a Gaussian distrib (group S)
  - Want to know the number of leaves in group S
  - Want to know the deviation of the $n_S$ from prediction (for numerical convenience)
  - Giving the likelihood of the data : [formula]
- Maximum likelihood point estimator
  - Easy with maximum likelihood !
- Invert statistical test to get a confidence set
  - The final objective is a confidence set (or interval)
  - We get it by inverting a statistical test.



Inverse problem
-------------------------------------------------------------------------------

!!!
    The first difficulty : Not a tracktable likelihood at sample level

- No likelihood at the sample level
  - Now the likelihood for $x$ is intractable in many interesting case
  - (which is the case fot the HEP experiments)
  - Because there is a very large number of latent variables
  - But it is possible to sample from a simulator
- Inverse problem
  - This leads to an inverse problem (inverting a simulator/sampler)
- Particular inverse problem -> looking for a mixture coefficient
- (or not) likelihood at the distribution level
  - But in our particular case an approximative model is available
  - Poisson count process as an approximation of counting iid Bernoulli rare process
  - The simulator is part of the model through $\gamma$ and $\beta$

!!!
    binning will be introduced later whith the classifier improvement.
    We now introduce systematics because it is more important.


Systematics
-------------------------------------------------------------------------------

!!!
    The second difficulty : systematic effect of the nuisance paramters


- What are systematics ?
  - Nuisance parameters are parameters required to fully describes the data generating process but not of direct interest
  - Systematic effect is the effect of nuisance parameters on the data
  - Update the 1D exampl :
    - Systematics = a small offset or scale factor on the ruler
      - (we go with the scale because it will be usefull later)
      - impossible to disentangle -> measured x = offset + true value or scale * true value
    - Objective = something related with the mean length of the leaves
    - Increases uncertainty on the final measurement
  - Calibration is required to partially disentangle the nuisance parameters and the parameter of interest
    - It is an additionnal information -> an additional measurement -> an additional likelihood
- Systematics always increases the confidence set volume
- Profiled likelihood method to take systematics into account in uncertainty measurement (volume of confidence set)


Classifier to improve binning
-------------------------------------------------------------------------------

- Binning is better !
  - A good idea to improve the inference is to do binning as long as the Poisson approx remains valid
  - show math proving that 2 bins is better no matter what threshold is used
  - show math proving that more bins is probably better too
  - best to have pure signal or pure background bin
- High dimensional data histogram is too expensive
  - Multi dimensional data usually cary more information
  - Unfortunately binning scales exponentially with increase of dimension
- dimension reduction
  - Need to find a good dimension reduction keeping most information about our parameter of interest
  - Can be crafted by hand but it requires domain knowledge and many work hours
  - hence the idea of using Machine learning
- Figure of merit is not a tracktable (additive) quantity (cannot use as a loss)
  - So we can use a proxy loss to train our ML model
  - Recall that separating S and B events is reduces the uncertainty -> classifiers
- Bayes optimal classifiers gives sufficient summary stat (no systematics setting)
- Systematics breaks Bayes optimal classifier garanty


Solutions and outline
-------------------------------------------------------------------------------

- Regularization to train a robust classifier
- Change cross-entropy for a lower bound of final uncertainty
- Direct regression (likelihood free setting)
- Mining data for nuisance parameters to improve model



!!! error
    HiggsML data est intro section 1 mais on en parle plus du tout après....

!!! error
    Le problème de comptage n'est pas assez mis en avant


Regularization
===============================================================================

!!! error
    Reprendre les papiers pour compléter

Add regularization to cross entropy loss
-------------------------------------------------------------------------------

- If the classifier output is independant from the nuisance parameters then we win !
  - If it is just less dependant it will still decrease the final uncertainty.



Data augmentation
-------------------------------------------------------------------------------


- Avantages / drawbacks summary



Tangent Propagation
-------------------------------------------------------------------------------

- Avantages / drawbacks summary


Pivotal neural networks
-------------------------------------------------------------------------------

- Related to the DANN but without unlabeled data
- Avantages / drawbacks summary



Performances ?
-------------------------------------------------------------------------------




Tackling the distribution
===============================================================================



Neural stat & inferno
-------------------------------------------------------------------------------

- Training neural networks to produce summary statistics
  - Permutation invariant architectures
  - Losses on summary stats (and on samples for neural stat)
- Training on a lower bound of the final uncetrainty
  - Cramer Rao bound
- Limitations (& possible solution)
  - Differentiable simulator
  - (Approximate derivative with tangent)
  - Reverse a large hessian matrix can be complicated
  - (Tackle only the systematic effects with most impact on inference)


Performances on toys ?
-------------------------------------------------------------------------------


Measuring uncertainty in ML
-------------------------------------------------------------------------------
- Importance of uncertainty in ML
- Mixture density networks
  - Predict parameters of distributions (exm : mean and variance of gaussian)
  - Training details
  - The dynamic of training is unusual
  - Adjust Adam parameters to reduce intertia
- Short review of more recent methods
  - MC-dropout
  - Deep ensembles
  - Swag (Stochastic weight averaging - Gaussian)
- Evaluation of uncertainty predictions in machine learning
  - Brier Score and NLL ("proper scoring" ?)
  - No real answer to "Can you trust your uncertainty estimation ?" (error on error)


Direct regression on empirical distribution
-------------------------------------------------------------------------------

- Motivation
  - Likelihood free
  - No differentiable simulator
  - Simpler (therefor less accurate)
  - Faster at inference
- Updating the architecture to tackle empirical distributions
  - Permutation invariant networks
  - Importance that sample size is representative of real data ?
- Include samples weights into the architecture
- Two ways to handle nuisance parameters
  - Ingore them (harder on the network)
  - Profile them (give as input and marginalize)
- These architectures are compatible with Inferno
  - can improve network expressivity



Performances ?
-------------------------------------------------------------------------------



Improve model / extract more info from data
===============================================================================


!!!
    Too short for a chapter ?

n_i are not sufficient
-------------------------------------------------------------------------------

- $n_i$ are not sufficient for $\alpha$
- Domain knowledge to extract other quantities ?
  - Yes, but it is likely in the calibration already !



Extract using a regressor
-------------------------------------------------------------------------------

- Data mining about distribution parameter without domain knowledge is exactly what direct regression from previous chapter is about.
- Updating the likelihood using this new measurement by simply add another likelihood to it.


Experimental results
-------------------------------------------------------------------------------

See the next chapter ?



Experimental results
===============================================================================

!!!
    Je rassemble les résultats ici.
    Mais en pratique je pense qu'une majorité devrait être distribuée tout le long du manuscrit.
    Ou bien envoyée en annexe.

First the results of the individual methods and a description of their behaviour.
Then comparing using the usual model.
Then comparing using the improved model.


!!! Tip
    Affirmations & interprétation / explications

Classifier
-------------------------------------------------------------------------------

- On 1D toy
  - similar to no dimension reduction (which is expected)
  - biased estimator (which is what we want to avoid)
  - performance depend a lot of sample size (which is expected)
-  On 3D toy
  - TODO
- On higgs
  - Completely broken. Inference fails.




Data augmentation
-------------------------------------------------------------------------------

- On higgs
  - Completely broken. Inference fails.


Tangent Propagation
-------------------------------------------------------------------------------

- On higgs
  - Completely broken. Inference fails.


Pioval network
-------------------------------------------------------------------------------

- On higgs
  - Completely broken. Inference fails.


Inferno
-------------------------------------------------------------------------------


- On higgs
  - It almost works
  - Sometimes close to constant prediction.


Direct regression
-------------------------------------------------------------------------------

- On 1D toy
  - Blind-reg is way better than the Param-Reg
  - Variance does not vary according to the number of samples



Claim : All methods works (mostly) as expected on toys
-------------------------------------------------------------------------------

- MSE decreases with increasing the number of samples (except Regressor)
- Non robust methods are sensitive to systematic effect
- 1D toy is very easy
  - Classifiers are (almost) optimal for dimension reduction but there is no reducton here
  - the problem could be solved with a linear regression



Claim : The difficulty on Higgs comes only from the rare signal regime (S << B)
-------------------------------------------------------------------------------

- XP showing that just balancing S and B makes the model's behaviour clother to their behaviour on toys
- XP showing that just un-balancing S and B on the toys makes the model's behaviour clother to their behaviour on Higgs



Claim : Extracting nuisance params info from data improves MSE and interval
-------------------------------------------------------------------------------

- On toys
- On higgs
  - the nuisance estimation is often overconfident !
- Models that does not takes much advantage from it are (maybe) doing it internally
  - Inferno could naturally use some of the bins for this purpose (the loss may encourage it)
  - The Blind-regresor could also do it (it is designed with the freedom of fully exploiting the data)
  - what about methods with regularization ? Why don't they also achieve this ?
    - regularized methods loss are expressed at a sample level
    - this information is not available at sample level but only on at a distribution level





Discussion and conclusion
===============================================================================





Lost and found
===============================================================================

- les résultas des XP
- Higgs re-simulator
- 1er Travaux sur sigma mu
- Insister sur le fait que S & B ne sont pas séparable (sinon c'est trop facile)
- Peut-être que le regresseur ne marche pas dans le régime S << B car le ML s'occupe de performance en moyenne et nous on cherche à mesurer un petit bump dans la queue de la distribution. C'est pas quelque chose de commun dans le ML.
- Est-ce que l'échec de Regressor sur Higgs (S << B) ne vient pas d'un sample size trop petit ? 10k events ça donne peut-être une "pente" à fit très variable d'un batch à l'autre !

- How it is done
  - hand crafted dimension reduction (ie ask a theorist to find a feature) is not always possible and requires a lot work hours
  - Poisson count process & binned Poisson count process
  - Although the model seems simple, most of it is in the simulator ie in the estimation of $\gamma$ and $\beta$
- Other methods exists but do not fit perfectly to our problem
  - ABC is likelihood free -> we have a likelihood
  - Variational inference -> is known to underestimate the uncertainty, and is looking for p(x) instead of p(mu|x)
  - Bayesian networks -> Other have tried ... need to check more in depth
  - Mining gold -> I do not have access to the simulator (proprietary code)





<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/dark.css?">
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script>markdeepOptions={tocStyle:'none'};</script>
<!-- Markdeep: --><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
