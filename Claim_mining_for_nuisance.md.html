<meta charset="utf-8" emacsmode="-*- markdown -*-">

**Claim : mining for nuisance parameters improves inference**

This document gather evidence that mining information about the nuisance parameter in the dataset improves inference.
Also note that it seems that some methods (INFERNO and Blind regressor) already exploit this advantage although they are not explicitly design for it.

Generalities
===============================================================================


Core idea
-------------------------------------------------------------------------------

The idea originally comes from a naive thought :
> If the systematic effect significantly impacts the data then we can *see* it.
> If we can *see* it then we can measure it.
> If it is measurable, then it can be compensated.
> if we can compensate it then there is no more systematic effect.

Of course this works only if the systematic effect and the studied phenomenom impact can be distinguished.
In real life it is impossible to fully the disentangle the nuisance parameters and parameter of interest impact on data.

But the classic pipeline is optimized in a setting without systematic effect.
The summary statistic ($n_i$) are especially optimized to contain most (if not all) the information about the parameter of interest.
But the information about the nuisance parameters is lost in the process and we have to rely on another measurement : the calibration.

Based on this observation, we propose to also extract information about nuisance parameter from the data.
The likelihood of the generating process is then updated to take this information into account.
The hope is that these new information improves inference ie reduced bias or shorten the confidence interval.


Place in story
-------------------------------------------------------------------------------


This document belong to the chapter about using direct regression to support the original pipeline.
So probably in the last chapter before discussion and conclusion.



Method
-------------------------------------------------------------------------------

To extract information about the nuisance parameter from the data the best way would be to levarage domain knowledge.
This would update the likelihood using new specialised measured quantities.
For example : the average of some hand crafted feature may be very corelated with some nuisance parameter but independant from the parameter of interest.
Unfortunately such advantages are probably already used and included in the calibration.

Meaning we should extract with no domain knowledge at all.
Which is exactly the purpose of the direct regression.

Assuming that the regression is working and the output distribution is a good approximation then we can add this to the generative process.

Updating the likelihood :
\begin{equation}
  L(\mu, \alpha) = L_{classic}(n_i | \mu, \alpha) \times L_{calibration}(C | \alpha) \times  L_{regression}(P | \alpha)
\end{equation}

Where $L_{classic}(n_i | \mu, \alpha)$ is the poisson likelihood ;
and $L_{calibration}(C | \alpha)$ is the calibration likelihood given by other experts ;
and $L_{regression}(P | \alpha)$ is the additional likelihood taking into account the new information extracted from the data.


!!! warning
    I should look into this later : the regressor is producing a posterior distribution and we use this posterior as a likelihood which feels weird and at least requires to be clarified.



Results on the 1D toy
===============================================================================

Reduces the bias of the maximum likelihood estimator
-------------------------------------------------------------------------------

The classifiers and other methods show biased estimators when the test data is not generated with the nominal values of the nuisance parameters.
See [another document] for details and fig. [fig:NN-prior] for an example.

![Figure [fig:NN-prior]: average of estimators from many Neural network classifier (different hyper-parameters) on 1D toy. Colors are related to the the true value of $\alpha$](./claim_mining_for_nuisance/NN_prior_profusion_true_mu_target_mean.png)


As seen in fig. [fig:NN-prior] the classifier are biased (blue and green points are always below the red target).
Of course the estimator on the nominal value (orange) is perfectly unbiased.

But in fig. [fig:NN-calib] the bias is almost zero.

![Figure [fig:NN-calib]:
  average of estimators from many Neural network classifier (different hyper-parameters) on 1D toy.
  Colors are related to the the true value of $\alpha$
](./claim_mining_for_nuisance/NN_calib_profusion_true_mu_target_mean.png)



This phenomenon is also present with regularized classifier as seen in Figure [fig:DA-prior] to Figure [fig:Pivot-calib]

![Figure [fig:DA-prior]: Data augmentation (classic)](./claim_mining_for_nuisance/DA_prior_profusion_true_mu_target_mean.png) ![Figure [fig:DA-calib]: Data augmentation (upgrade)](./claim_mining_for_nuisance/DA_calib_profusion_true_mu_target_mean.png)
![Figure [fig:Pivot-prior]: Pivot (classic)](./claim_mining_for_nuisance/Pivot_prior_profusion_true_mu_target_mean.png) ![Figure [fig:Pivot-calib]: Pivot (upgrade)](./claim_mining_for_nuisance/Pivot_calib_profusion_true_mu_target_mean.png)

And the Parametrised-regresor.

![Figure [fig:Param-Reg-prior]: Param-Regressor (classic)](./claim_mining_for_nuisance/Param-Reg_prior_profusion_true_mu_target_mean.png) ![Figure [fig:Param-Reg-calib]: Param-Regressor (upgrade)](./claim_mining_for_nuisance/Param-Reg_calib_profusion_true_mu_target_mean.png)


Reduces the length of the confidence interval
-------------------------------------------------------------------------------

From looking into it and reading the numbers it seems to be true especially when the number of samples is small.
But I need to make a few plots that better illustrate it and is easier to read than the current ones.

!!!
    TODO : make sigma plots easier to read ! (fix scale)


!!!
    TODO : What about the variance of the maximum likelihood estimator ?
    Does it behave the same as the confidence interval ?




Results on higgs
===============================================================================

!!!
    TODO !




Methods doing it anyway
===============================================================================

!!! error
    ugly title


Blind regressor
-------------------------------------------------------------------------------

Of course the Blind regressor ignores the calibration information and only uses the empirical distribution.
It is natural to think that such method is incline to internally measure the nuisance parameter or at least disentangle it from its target : the parameter of interest.




Inferno
-------------------------------------------------------------------------------

Inferno could use some of the bins to be very sensitive to the nuisance parameter.
If some $n_i$ are very sensitye to $\alpha$ then the maximizing the likelihood requires to be close to the true $\alpha$.

!!! error
    C'est un peu maladroitement expliqu√©...

It seems that inferno is not biased on the 1D toy.
But also Inferno does not improves much from this new information.
So maybe it is because it already *knows* about it.




<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/dark.css?">
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
