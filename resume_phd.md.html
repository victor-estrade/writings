<meta charset="utf-8" emacsmode="-*- markdown -*-">

**Resume**



BACKGROUND AND MOTIVATIONS:
===========================

The objective of the thesis is
to improve the integration of machine learning methods in complex statistical inference pipeline
in the context of
a High Energy Physics analysis at the Large Hadron Collider.

This problem is particularly important because
experimental science now have to cope with huge amount of multidimensional data
challenging the manpower efficiency of classical hand crafted methods.

Although it has been addressed in the past by
[… ???]

in restricted and/or related cases such as
[… ???]

we tackle novel aspects of it, namely
taking into account the impact of training under the distribution shift induced by nuisance parameters
which was not studied before. Furthermore, we cast the problem into a novel framework
[… ???]

clarifying the subject with respect to
[… ???]

and we propose and compare machine learning methods against established methods, such as
standard classification or inference on the most promissing feature.

We are uniquely positioned to address this problem because
this work follows the "wave" created by the higgsML challenge.


MATERIAL AND METHODS:
=====================

To demonstrate advances on this problem, we use
the publicly available higgsML challenge
“real” data (data obtained with a realistic simulator),
enhanced with a re-simulation process, develloped for this project,
recomputing all the attributes as if the full simulation were re-ran with different input parameters.

We also conduct systematic experiments on a set of smaller didactic examples to clarify the following points :
- impact of signal/background ratio
- variance analysis of the maximum likelihood estimator
- impact of the number of nuisance parameters (bof)

We benchmark 8 methods. Including
standard classifiers, data augmentation, tangent propagation, pivotal neural network, inference aware neural optimization network, direct regression.
The experiments are carried out on a 30+ GPU cluster.

In addition, several theoretical insights are obtained by analyzing successes and failures in numerical experiments. We derived several properties of
[… ???]

using mathematics of statistics techniques
[… ???]


RESULTS:
========

Our results on realistic synthetic data demonstrate that
robustness to systematic effect improves performances if the regularization is not too strong
and the suitability of direct regression for inference.

One particular highlight is:
the evidence that the robustness of INFERNO to systematic effect is similar to the extraction of nuisance parameters related information from the data.

This opens the door to:
[… ]

We noticed that, contrarily to results on smaller artificial examples, we have on realistic synthetic the following behavior
[… ???]

This prompted us to make a more in depth and detailed study using artificial data, which revealed:
[… ???]

This was further substantiated with a theoretical analysis. We proved that
carefully choosing the binning procedure is critical (but it is not new at all !).

analytically. Although such theoretical results are limited by a given set of assumptions
 : the lack of nuisance parameter
,
they are corroborated by numerical experiments in the broader setting
[… ???]

This leads us to conclude with confidence that
having a very signal/background ratio makes the inference extremely difficult for all methods
and extracting more information about the nuisance parameters always improve the resulting confidence interval.
This is the main result of this thesis.

We also conducted an analysis of the computational efficiency of the algorithms revealing that:
tangent propagation suffers from the lack of jacobian vector product in common libraries,
INFERNO can fully leverage GPU computing and is very accurate,
data augmentation shows good accuracy and does not requires GPU oriented machines,
and although direct regression is compuationnaly intensive for training its inference speed is unmached.


CONCLUSION AND FURTHER WORK:
============================

This work allowed us to advance the field of
integrating machine learning into statistical analysis

in a number of directions, including
reducing nuisance parameters influence on the final uncertainty,
opening the replacements of more parts of the pipeline by specialized neural network,
and the importance of data mining various informations to impove modelization.


The framework we proposed helped us clarify and unify past work and allowed us to identify critics difficulties not anticipated, such as
[… ]

[… ]

With perseverance, we managed to understand such issues and resolve a number of them using
[… ]

[… ]

But much work remains to be done to improve
integration of the final objective figure of merit when the simulator is not differentiable,
automating relevant summary statistics extraction,
and ensuring the quality of the uncertainty predicted by neural network direct regression.

Further research directions include
extacting more information from the simulator (madminer/mining gold),
ensemble of neural networks for better measurement of the uncertainty (stochastic weight averaging seems promissing),
and robustness to nuisance parameters in a likelihood free inference framework.



MAIN CONTRIBUTIONS (at least 5 points):
=======================================

(TODO developper ces points, ne pas juste les citer.)

In summary, the main contributions of this thesis are:
- clarifying the interactions between the classifiers and the systematic effects
  - impact of training under parametrized shift
- comparison of the various systematic aware methods
  - impact of various proxy loss and regularization
- direct regression on empirical distribution
- improving the inference by extracting more information from the data
- ???



NOTES
=====

Ne pas se focaliser sur les stats.
Entre nous on sait la partie ML donc on en parle pas.
Mais ici c'est du ML qui doit ressortir.

Idée du Neural stat -> les exemples individuels ne donne pas d'info.
C'est les ensembles qui contiennent l'info.

C'est pas du transfert...
Reprendre le sujet de thèse (document de départ) et le mettre à jour.
Reprendre le papier de NIPS workshop version longue.
Supervisé vs non-supervisé -> on veut valider la méthode (sur les simulations)

Gap Réalité/Simulation -> transfert learning
Transfert = utiliser les données réelles, sauf qu'on a besoin de valider le modèle...
Mais comment valider un modèle utilisant les données réelle.
Out of scope / trop dur / trop long de changer la méthode de validation du modèle/pipeline.

Reg-Mamouth est à mettre en parallele ou en continuité d'INFERNO.

Manque error stat et error syst dans le discours.
Quid de l'influence de $\gamma << \beta$ sur error stat/syst ?

Remarks
-------

Définir en tant que problème de ML :
- shift paramétrisé de la distribution de test. Multi param et non reversible. à la fin on a quand même qu'une valeur dans le test set.
- Une forme de réduction de dimension ou de construction de summary stat
- fonction objectif complexe (pas calculable). c'est réduire la taille l'interval de confiance *proxy loss*

Les questions abordées :
- How to train on a data bunch instead of data sample ?
- How to train when the training distribution is "wrong" ?
- How to train with intractable loss function ?
- Measuring the Impact of training on a shifted distribution on a complex loss
- comparing methods according to real objective instead of proxy.


- On a pu éclaircir les interactions entre le ML et les systématiques




<link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/dark.css?">
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script>markdeepOptions={tocStyle:'none'};</script>
<!-- Markdeep: --><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
